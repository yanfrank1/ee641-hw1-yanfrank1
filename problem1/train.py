# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KEeyPPFfEoS2smPIV_uBx1rYmEZmoILA
"""

import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from dataset import ShapeDetectionDataset
from model import MultiScaleDetector
from loss import DetectionLoss
from utils import generate_anchors, compute_iou
from evaluate import compute_ap, visualize_detections, analyze_scale_performance
import json
import os

def train_epoch(model, dataloader, criterion, optimizer, device, anchors):
    """Train for one epoch."""
    model.train()
    # Training loop
    total_loss = 0.0

    for images, targets in dataloader:
        images = images.to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        optimizer.zero_grad()
        outputs = model(images)
        loss_dict = criterion(outputs, targets, anchors)
        loss = loss_dict['loss_total']
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    return total_loss / len(dataloader)
    pass

def validate(model, dataloader, criterion, device, anchors):
    """Validate the model."""
    model.eval()
    total_loss = 0.0
    all_predictions = []
    all_ground_truths = []
    with torch.no_grad():
        for images, targets in dataloader:
            images = images.to(device)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            outputs = model(images)
            loss_dict = criterion(outputs, targets, anchors)
            total_loss += loss_dict['loss_total'].item()
            for b in range(len(images)):
                boxes, scores, labels = [], [], []
                for scale_idx, output in enumerate(outputs):
                    _, _, H, W = output.shape
                    output = output[b]
                    output = output.permute(1, 2, 0).reshape(H * W * 3, -1)
                    scale_anchors = anchors[scale_idx].to(output.device)
                    cxcy = output[:, :2]
                    wh = output[:, 2:4]
                    objectness = torch.sigmoid(output[:, 4])
                    class_scores = torch.sigmoid(output[:, 5:])
                    score, label = class_scores.max(dim=1)
                    score = score * objectness
                    keep = score > 0.3
                    if keep.sum() == 0:
                        continue
                    scale_anchors = scale_anchors[keep]
                    cxcy = cxcy[keep]
                    wh = wh[keep]
                    score = score[keep]
                    label = label[keep]
                    anchor_wh = scale_anchors[:, 2:] - scale_anchors[:, :2]
                    anchor_cxcy = (scale_anchors[:, 2:] + scale_anchors[:, :2]) * 0.5
                    pred_cxcy = cxcy * anchor_wh + anchor_cxcy
                    pred_wh = wh.exp() * anchor_wh
                    pred_cxcy = torch.clamp(pred_cxcy, 0, 224)
                    pred_wh = torch.clamp(pred_wh, 1, 224)
                    box_xy1 = pred_cxcy - 0.5 * pred_wh
                    box_xy2 = pred_cxcy + 0.5 * pred_wh
                    box = torch.cat([box_xy1, box_xy2], dim=1)
                    boxes.append(box)
                    scores.append(score)
                    labels.append(label)

                if boxes:
                    boxes = torch.cat(boxes)
                    scores = torch.cat(scores)
                    labels = torch.cat(labels)
                    keep_all = []
                    for c in labels.unique():
                        idx = (labels == c).nonzero(as_tuple=True)[0]
                        if idx.numel() == 0:
                            continue
                        k = nms(boxes[idx], scores[idx], iou_threshold=0.5)
                        keep_all.append(idx[k])
                    if keep_all:
                        keep_all = torch.cat(keep_all)
                        boxes = boxes[keep_all]
                        scores = scores[keep_all]
                        labels = labels[keep_all]
                    else:
                        boxes = torch.empty((0, 4), device=boxes.device)
                        scores = torch.empty((0,), device=scores.device)
                        labels = torch.empty((0,), dtype=torch.long, device=labels.device)
                    all_predictions.append({
                        'boxes': boxes.cpu(),
                        'scores': scores.cpu(),
                        'labels': labels.cpu()
                    })
                else:
                    all_predictions.append({
                        'boxes': torch.empty((0, 4)),
                        'scores': torch.empty((0,)),
                        'labels': torch.empty((0,), dtype=torch.long)
                    })

            for i in range(len(images)):
                all_ground_truths.append({
                    'boxes': targets[i]['boxes'].cpu(),
                    'labels': targets[i]['labels'].cpu()
                })
    avg_loss = total_loss / len(dataloader)
    return avg_loss, all_predictions, all_ground_truths
    pass

def collate_fn(batch):
    images, targets = zip(*batch)
    images = torch.stack(images, dim=0)
    return images, targets

def nms(boxes, scores, iou_threshold=0.5):
    keep = []
    id = scores.argsort(descending=True)
    while id.numel() > 0:
        i = id[0]
        keep.append(i.item())
        if id.numel() == 1:
            break
        ious = compute_iou(boxes[i].unsqueeze(0), boxes[id[1:]])[0]
        id = id[1:][ious <= iou_threshold]
    return torch.tensor(keep, dtype=torch.long, device=boxes.device)

def main():
    # Configuration
    batch_size = 16
    learning_rate = 0.001
    num_epochs = 50
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    os.makedirs('results', exist_ok=True)

    # Initialize dataset, model, loss, optimizer
    # Training loop with logging
    # Save best model and training log
    train_img_dir = 'datasets/detection/train'
    train_ann_file = 'datasets/detection/train_annotations.json'
    val_img_dir = 'datasets/detection/val'
    val_ann_file = 'datasets/detection/val_annotations.json'

    train_dataset = ShapeDetectionDataset(train_img_dir, train_ann_file)
    val_dataset = ShapeDetectionDataset(val_img_dir, val_ann_file)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)
    model = MultiScaleDetector(num_classes=3, num_anchors=3).to(device)
    criterion = DetectionLoss(num_classes=3)
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)
    feature_map_sizes = [(56, 56), (28, 28), (14, 14)]
    anchor_scales = [[16, 24, 32], [48, 64, 96], [96, 128, 192]]
    anchors = generate_anchors(feature_map_sizes, anchor_scales, image_size=224)
    anchors = [a.to(device) for a in anchors]
    best_val_loss = float('inf')
    history = {'train_loss': [], 'val_loss': [], 'ap_per_class': []}

    for epoch in range(num_epochs):
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, anchors)
        val_loss, val_predictions, val_ground_truths = validate(model, val_loader, criterion, device, anchors)
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        print(f"[Epoch {epoch+1:02d}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
        ap_per_class = []
        for c in range(3):
            aps = []
            for preds, gts in zip(val_predictions, val_ground_truths):
                preds_c = {
                    "boxes": preds["boxes"][preds["labels"] == c],
                    "scores": preds["scores"][preds["labels"] == c],
                    "labels": preds["labels"][preds["labels"] == c]
                }
                gts_c = {
                    "boxes": gts["boxes"][gts["labels"] == c],
                    "labels": gts["labels"][gts["labels"] == c]
                }
                ap = compute_ap(preds_c, gts_c, iou_threshold=0.5)
                aps.append(ap)
            ap_per_class.append(sum(aps)/len(aps) if len(aps) > 0 else 0.0)
        history['ap_per_class'].append([float(x) for x in ap_per_class])

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), 'results/best_model.pth')

        torch.save(val_predictions, 'results/val_predictions.pt')
        torch.save(val_ground_truths, 'results/val_ground_truths.pt')

    with open('results/training_log.json', 'w') as f:
        json.dump(history, f, indent=2)
    model.eval()
    os.makedirs("results/visualizations/detections", exist_ok=True)
    idx = 1
    with torch.no_grad():
        for images, targets in val_loader:
            images = images.to(device)
            outputs = model(images)
            for i in range(len(images)):
                image = images[i].cpu().permute(1, 2, 0).numpy() * 255
                image = Image.fromarray(image.astype('uint8'))
                gt = {
                    "boxes": targets[i]["boxes"],
                    "labels": targets[i]["labels"]
                }
                all_boxes, all_scores, all_labels = [], [], []
                for scale_idx, preds in enumerate(outputs):
                    pred = preds[i]
                    C, H, W = pred.shape
                    pred = pred.view(3, 8, H, W).permute(0, 2, 3, 1).reshape(-1, 8)
                    anchor = anchors[scale_idx]
                    anchor = anchor[:pred.shape[0]]
                    cxcy = pred[:, :2]
                    wh = pred[:, 2:4]
                    objectness = torch.sigmoid(pred[:, 4])
                    class_scores = torch.sigmoid(pred[:, 5:])
                    score, label = class_scores.max(dim=1)
                    score = score * objectness
                    anchor_wh = anchor[:, 2:] - anchor[:, :2]
                    anchor_cxcy = (anchor[:, 2:] + anchor[:, :2]) * 0.5
                    pred_cxcy = cxcy * anchor_wh + anchor_cxcy
                    pred_wh = wh.exp() * anchor_wh
                    xy1 = pred_cxcy - 0.5 * pred_wh
                    xy2 = pred_cxcy + 0.5 * pred_wh
                    box = torch.cat([xy1, xy2], dim=1)
                    mask = score > 0.3
                    box, score, label = box[mask], score[mask], label[mask]
                    keep_all = []
                    for c in label.unique():
                        idxc = (label == c).nonzero(as_tuple=True)[0]
                        if idxc.numel() == 0:
                              continue
                        k = nms(box[idxc], score[idxc], iou_threshold=0.5)
                        keep_all.append(idxc[k])
                    if len(keep_all) > 0:
                        keep_all = torch.cat(keep_all)
                        box, score, label = box[keep_all], score[keep_all], label[keep_all]
                    else:
                        box = torch.empty((0,4), device=box.device)
                        score = torch.empty((0,), device=score.device)
                        label = torch.empty((0,), dtype=torch.long, device=label.device)
                    all_boxes.append(box)
                    all_scores.append(score)
                    all_labels.append(label)
                boxes = torch.cat(all_boxes)
                scores = torch.cat(all_scores)
                labels = torch.cat(all_labels)
                preds = {"boxes": boxes.cpu(), "scores": scores.cpu(), "labels": labels.cpu()}
                visualize_detections(image, preds, gt, f"results/visualizations/detections/{idx}.png")
                idx += 1
                if idx > 10:
                    break
            if idx > 10:
                break

    os.makedirs("results/visualizations/anchor_coverage", exist_ok=True)
    fig, ax = plt.subplots(figsize=(6,6))
    cx, cy = 112, 112
    ax.scatter(cx, cy, color='black', label='Anchor Center')
    colors = ['blue', 'orange', 'green', 'red', 'purple']
    for idx, scale in enumerate(anchor_scales):
        for s in scale:
            w, h = s, s
            x1, y1 = cx - w/2, cy - h/2
            rect = patches.Rectangle((x1, y1), w, h, linewidth=2,
                                     edgecolor=colors[idx % len(colors)],
                                     facecolor='none', linestyle='--')
            ax.add_patch(rect)
        ax.plot([], [], color=colors[idx % len(colors)], linestyle='--', label=f"Scale {idx+1}")
    ax.set_xlim(cx-100, cx+100)
    ax.set_ylim(cy-100, cy+100)
    ax.set_title("Anchor Coverage at Single Position")
    ax.legend()
    plt.savefig("results/visualizations/anchor_coverage/Coverage.png")
    plt.close()

    analyze_scale_performance(model, val_loader, anchors, device)
    pass

if __name__ == '__main__':
    main()